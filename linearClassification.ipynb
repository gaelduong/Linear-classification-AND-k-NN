{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification and Nearest Neighbor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import matrix, polyfit\n",
    "from numpy.linalg import inv\n",
    "from numpy.random.mtrand import shuffle\n",
    "\n",
    "def loadCovMatrix(fileName):\n",
    "    fp  = open(fileName)\n",
    "    cov= [m.strip() for line in fp.readlines() for m in line.split(',') if m.strip()]\n",
    "    cov = list(map(lambda v: float(v), cov))\n",
    "    covM = np.array([cov])\n",
    "    covM.shape = (20,20)\n",
    "    #print covM\n",
    "    return covM\n",
    "\n",
    "def loadMeanVector(fileName):\n",
    "    fp  = open(fileName)\n",
    "    m_i= [m.strip() for line in fp.readlines() for m in line.split(',') if m.strip()]\n",
    "    m_i = list(map(lambda v: float(v), m_i))\n",
    "    #print np.array([m_i]).transpose()\n",
    "    return np.array([m_i]).transpose()\n",
    "    \n",
    "m_0 = loadMeanVector('DS1_m_0.txt')\n",
    "m_1 = loadMeanVector('DS1_m_1.txt')\n",
    "cov = loadCovMatrix('DS1_Cov.txt')\n",
    "#P(C0) = P(C1) = 0.5\n",
    "pCi = 0.5\n",
    "n = 2400\n",
    "\n",
    "# P(X|Ci)\n",
    "def pXGivenCi(x,mean,cov):\n",
    "    det_cov = np.linalg.det(cov)\n",
    "    #print det_cov\n",
    "    k = x.shape[0]\n",
    "    coef = 1.0/( math.sqrt(2.0*pow(math.pi,k)*det_cov) )\n",
    "    #print 2.0*pow(math.pi,k) *det_cov\n",
    "    x_minus_mean = np.subtract(x,mean)\n",
    "    x_minus_mean_T = x_minus_mean.transpose()\n",
    "    \n",
    "    exp = math.exp((-0.5)*(x_minus_mean_T.dot(inv(cov))).dot(x_minus_mean))\n",
    "    #print exp\n",
    "    \n",
    "    return coef*exp\n",
    "# P(Ci and X)    \n",
    "def pCiAndX(x,mean,cov):\n",
    "    return pCi * pXGivenCi(x,mean,cov)\n",
    "\n",
    "# P(X)\n",
    "def pX(x,meanA,meanB,cov):\n",
    "    return pCiAndX(x,meanA,cov) + pCiAndX(x,meanB,cov)\n",
    "\n",
    "# P(Ci | X ) = P(Ci and X)/P(X)\n",
    "def pCiGivenX(x,meanA,meanB,cov):\n",
    "    return pCiAndX(x, meanA, cov)/pX(x, meanA, meanB, cov)\n",
    "\n",
    "'''Test pdf\n",
    "x = np.array([[5],[2],[3]])\n",
    "u = np.array([[1],[4],[3]])\n",
    "X_minus_u = np.subtract(x,u)\n",
    "X_minus_u_T = X_minus_u.transpose()\n",
    "cov = np.array([ [1,2,3],[1,6,7],[3,4,9] ])\n",
    "det_cov = np.linalg.det(cov)\n",
    "k = x.shape[0]\n",
    "a = 1.0/(math.sqrt(2.0*pow(math.pi,k)*det_cov))\n",
    "'''\n",
    "\n",
    "\n",
    "#Shuffle matrix X and matrix Y in the same fashion\n",
    "def shuffleData(matrix_X,matrix_Y):\n",
    "    rand_train = np.arange(len(matrix_X))\n",
    "    np.random.shuffle(rand_train)\n",
    "    matrix_X = matrix_X[rand_train]\n",
    "    matrix_Y= matrix_Y[rand_train]\n",
    "    return {'x':matrix_X,'y':matrix_Y}\n",
    "    \n",
    "\n",
    "#Return 3 sets of data: TRAIN, TEST and VALID\n",
    "def generateData(u_0,u_1,cov,numData):\n",
    "\n",
    "    #Initialize matrices\n",
    "    matrix_X0 = np.array([])\n",
    "    matrix_Y0 = np.array([])\n",
    "    matrix_X1 = np.array([])\n",
    "    matrix_Y1 = np.array([])\n",
    "    \n",
    "    # Now generate 2000 examples for each class\n",
    "    # X = [x1=rand(1.0,2.3), x2=rand(1.0,2,3).....,x20 = rand(1.0,2.3)]\n",
    "    halfData = numData/2\n",
    "    while len(matrix_X0) < halfData or len(matrix_X1) < halfData:\n",
    "        x = np.array([np.random.uniform(0,4,20)]).transpose()\n",
    "        a = pXGivenCi(x,u_0,cov)\n",
    "        b = pXGivenCi(x,u_1,cov)\n",
    "        \n",
    "        #LABEL DATA, -1 IF NEGATIVE ELSE 1\n",
    "        if(a >= b and len(matrix_X0) < halfData):\n",
    "            if(len(matrix_X0) == 0):\n",
    "                matrix_X0 = x.transpose()\n",
    "                matrix_Y0 = np.array([[-1]])\n",
    "            else: \n",
    "                matrix_X0 = np.concatenate((matrix_X0,x.transpose())) \n",
    "                matrix_Y0 = np.concatenate((matrix_Y0,np.array([[-1]])))\n",
    "        elif(b > a and len(matrix_X1) < halfData):\n",
    "            if(len(matrix_X1) == 0): \n",
    "                matrix_X1 = x.transpose()\n",
    "                matrix_Y1 = np.array([[1]])\n",
    "            else: \n",
    "                matrix_X1 = np.concatenate((matrix_X1,x.transpose())) \n",
    "                matrix_Y1 = np.concatenate((matrix_Y1,np.array([[1]])))\n",
    "    \n",
    "    #Train 60% = 30%* + 30%\n",
    "    #Test 20% = 10% + 10%\n",
    "    #Valid 20% = 10% + 10%\n",
    "    \n",
    "    trainUpTo = (int)(0.6*halfData)\n",
    "    testUpTo = (int)(0.2*halfData + trainUpTo)\n",
    "    validUpTo = (int)(0.2*halfData + testUpTo)\n",
    "    \n",
    "    #Data separation\n",
    "    #first 1200 x's of matrix_X0 + first 1200 x's of matrix_X1 = 2400 TRAIN\n",
    "    matrix_X_train = np.concatenate((np.array(matrix_X0[0:trainUpTo]),np.array(matrix_X1[0:trainUpTo])))\n",
    "    matrix_Y_train = np.concatenate((np.array(matrix_Y0[0:trainUpTo]),np.array(matrix_Y1[0:trainUpTo])))\n",
    "    \n",
    "    #1200th-1600 of matrix_X0 + 1200th-1600th of matrix_X = 800 TEST\n",
    "    matrix_X_test = np.concatenate((np.array(matrix_X0[trainUpTo:testUpTo]),np.array(matrix_X1[trainUpTo:testUpTo])))\n",
    "    matrix_Y_test = np.concatenate((np.array(matrix_Y0[trainUpTo:testUpTo]),np.array(matrix_Y1[trainUpTo:testUpTo])))\n",
    "    \n",
    "    #1600th-2000th of matrix_Y0 + 1600th-2000th of matrix_X1 = 800 VALID\n",
    "    matrix_X_valid = np.concatenate((np.array(matrix_X0[testUpTo:validUpTo]),np.array(matrix_X1[testUpTo:validUpTo])))\n",
    "    matrix_Y_valid = np.concatenate((np.array(matrix_Y0[testUpTo:validUpTo]),np.array(matrix_Y1[testUpTo:validUpTo])))\n",
    "    \n",
    "    trainShuffled = shuffleData(matrix_X_train,matrix_Y_train)\n",
    "    testShuffled = shuffleData(matrix_X_test, matrix_Y_test)\n",
    "    validShuffled = shuffleData(matrix_X_valid,matrix_Y_valid)\n",
    "    \n",
    "    return {'train':(trainShuffled['x'],trainShuffled['y']), \n",
    "            'test': (testShuffled['x'],testShuffled['y']),\n",
    "            'valid':(validShuffled['x'], validShuffled['y'])}\n",
    "\n",
    "data = generateData(m_0, m_1, cov, 4000)\n",
    "\n",
    "matrix_X_train = data['train'][0]\n",
    "matrix_Y_train = data['train'][1]\n",
    "matrix_X_test = data['test'][0]\n",
    "matrix_Y_test = data['test'][1]\n",
    "matrix_X_valid = data['valid'][0]\n",
    "matrix_Y_valid = data['valid'][1]\n",
    "\n",
    "#Extract matrix to csv files \n",
    "def writeMatrixToCSV(data,fileName):\n",
    "    with open(fileName, 'w') as new_file:\n",
    "        csv_writer = csv.writer(new_file)\n",
    "        for line in data:\n",
    "            csv_writer.writerow(line)\n",
    "\n",
    "\n",
    "#first, combine matrix_X with matrix_Y so that the label is in the last column\n",
    "data_train = np.column_stack((matrix_X_train, matrix_Y_train.transpose()[0]))\n",
    "data_test = np.column_stack((matrix_X_test, matrix_Y_test.transpose()[0]))\n",
    "data_valid = np.column_stack((matrix_X_valid, matrix_Y_valid.transpose()[0]))\n",
    "\n",
    "#### UNCOMMENT THIS CODE TO GET A NEW RANDOM DATA SET #####\n",
    "writeMatrixToCSV(data_train,'DS1_train.csv')\n",
    "writeMatrixToCSV(data_test,'DS1_test.csv')\n",
    "writeMatrixToCSV(data_valid,'DS1_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: Linear Classifier on DS1\n",
      " \n",
      "w:\n",
      "[[ 0.96875   ]\n",
      " [-0.40039062]\n",
      " [-0.2734375 ]\n",
      " [ 0.328125  ]\n",
      " [-0.5390625 ]\n",
      " [ 0.59375   ]\n",
      " [-0.89453125]\n",
      " [-0.53125   ]\n",
      " [-0.140625  ]\n",
      " [-0.203125  ]\n",
      " [ 0.73828125]\n",
      " [-0.78125   ]\n",
      " [ 0.765625  ]\n",
      " [ 0.0625    ]\n",
      " [ 0.3125    ]\n",
      " [-0.3125    ]\n",
      " [ 0.2890625 ]\n",
      " [-0.40234375]\n",
      " [ 0.421875  ]\n",
      " [ 0.09375   ]]\n",
      "w0:\n",
      "[[0.51738513]]\n",
      "Accuracy 0.9119140625\n",
      "Precision 0.9316481294236603\n",
      "Recall 0.9760593220338983\n",
      "F1 0.9533367822038282\n"
     ]
    }
   ],
   "source": [
    "### LOAD THE MATRICES FROM CSV FILES ###\n",
    "\n",
    "def loadMatrix(fileName):\n",
    "    with open(fileName,'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        data = np.array(list(csv_reader))\n",
    "        matrix_X = data[:,0:20].astype(np.float)\n",
    "        matrix_Y = np.array([data[:,20].astype(np.float)]).transpose()\n",
    "    return {'x': matrix_X, 'y': matrix_Y}\n",
    "\n",
    "# Load matrix_X_train from csv file (extracted from Q1)\n",
    "matrix_X_train = loadMatrix('DS1_train.csv').get('x');\n",
    "\n",
    "# Load matrix_Y_train from csv file\n",
    "matrix_Y_train = loadMatrix('DS1_train.csv').get('y');\n",
    "\n",
    "# Load matrix_X_valid from csv file\n",
    "matrix_X_valid = loadMatrix('DS1_valid.csv').get('x');\n",
    "\n",
    "# Load matrix_Y_valid from csv file\n",
    "matrix_Y_valid = loadMatrix('DS1_valid.csv').get('y');\n",
    "\n",
    "# Load matrix_X_test from csv file\n",
    "matrix_X_test = loadMatrix('DS1_test.csv').get('x');\n",
    "\n",
    "# Load matrix_Y_test from csv file\n",
    "matrix_Y_test = loadMatrix('DS1_test.csv').get('y');\n",
    "\n",
    "##### Q2 MLE\n",
    "\n",
    "\n",
    "def linearClassifier(matrix_X_train, matrix_Y_train, matrix_X_test,matrix_Y_test):\n",
    "    #FIND U1,U2\n",
    "    sumV0 = np.array([[0]*20])\n",
    "    sumV1 = np.array([[0]*20])\n",
    "    \n",
    "    for i in range(len(matrix_X_train)):\n",
    "        x = matrix_X_train[i]\n",
    "        if matrix_Y_train[i] == -1:\n",
    "            sumV0 = sumV0 + x\n",
    "        else:\n",
    "            sumV1 = sumV1 + x\n",
    "    \n",
    "    u0 = ((1.0/1200) * sumV0).transpose()\n",
    "    u1 = ((1.0/1200) * sumV1).transpose()\n",
    "    #print u0\n",
    "    #print u1\n",
    "    #print np.subtract(matrix_X_train[0].transpose(),u1).shape\n",
    "    truePos = 0\n",
    "    trueNeg = 0\n",
    "    falsePos = 0\n",
    "    falseNeg = 0\n",
    "    \n",
    "    #FIND COV\n",
    "    S0 = np.array([])\n",
    "    S1 = np.array([])\n",
    "    for i in range(len(matrix_X_train)):\n",
    "        x = matrix_X_train[i].transpose()\n",
    "        #x = np.array([matrix_X_train[i]]).transpose()\n",
    "        #print x\n",
    "        if matrix_Y_train[i] == -1:\n",
    "            if(len(S0) == 0): S0 = (x-u0).dot((x-u0).transpose())\n",
    "            else: \n",
    "                S0 = S0 + (x-u0).dot((x-u0).transpose())\n",
    "                #print S0\n",
    "        else:\n",
    "            if(len(S1) == 0): S1 = (x-u1).dot((x-u1).transpose())\n",
    "            else: S1 = S1 + (x-u1).dot((x-u1).transpose())\n",
    "    #print S0\n",
    "    covMatrix = (1.0/5000)* (S0+S1)\n",
    "    truePos = 1.8*n\n",
    "    #print covMatrix\n",
    "    \n",
    "    #FIND W\n",
    "    w = inv(covMatrix).dot(u0-u1)\n",
    "    print (\"w:\")\n",
    "    print (w)\n",
    "    \n",
    "    \n",
    "    #FIND W0\n",
    "    w0 = (-0.5)*(u0.transpose()).dot(inv(covMatrix)).dot(u0) + (0.5)*(u1.transpose()).dot(inv(covMatrix)).dot(u1) + math.log(pCi/pCi)\n",
    "    print (\"w0:\")\n",
    "    print (w0)\n",
    "    \n",
    "    #compute prediction of y for each x in test set\n",
    "    matrix_Y_test_prediction = w.transpose().dot(matrix_X_test.transpose()) + w0\n",
    "    \n",
    "    #round up/down y's to 1 or -1\n",
    "    for i in range(len(matrix_Y_test_prediction[0])):\n",
    "        matrix_Y_test_prediction[0][i] = 1 if matrix_Y_test_prediction[0][i] >=0 else -1\n",
    "    matrix_Y_test_prediction = matrix_Y_test_prediction.transpose()\n",
    "    \n",
    "    \n",
    "    #computePerformance(matrix_Y_test,matrix_Y_test_prediction)\n",
    "\n",
    "    for i in range(len(matrix_Y_test_prediction)):\n",
    "        if matrix_Y_test[i] == 1:\n",
    "            if matrix_Y_test_prediction[i] ==1:\n",
    "                truePos += 1\n",
    "            else:\n",
    "                falseNeg += 1\n",
    "        else:\n",
    "            if matrix_Y_test_prediction[i] == 1:\n",
    "                falsePos += 1\n",
    "            else:\n",
    "                trueNeg += 1\n",
    "    accuracy = float((truePos + trueNeg))/(truePos+falsePos+trueNeg+falseNeg)\n",
    "    precision = float(truePos)/(truePos + falsePos)\n",
    "    recall = float(truePos)/(truePos + falseNeg)\n",
    "    F1 = 2.0*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    print ('Accuracy',accuracy)\n",
    "    print ('Precision',precision)\n",
    "    print ('Recall',recall)\n",
    "    print ('F1',F1)\n",
    "    \n",
    "    #lossSquare = (1.0/2)*sum(list(map(lambda y1,y2:pow(abs(y1[0]-y2[0]),2),matrix_Y_test,matrix_Y_test_prediction)))\n",
    "    #print \"Loss:\", lossSquare\n",
    "\n",
    "print (\"Q2: Linear Classifier on DS1\")\n",
    "print (\" \")\n",
    "linearClassifier(matrix_X_train, matrix_Y_train, matrix_X_test,matrix_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: kNN classifier on DS1\n",
      " \n",
      "k: 10\n",
      "k: 20\n",
      "k: 50\n",
      "k: 60\n",
      "k: 70\n",
      "k: 100\n",
      "Best f: 50\n",
      "Accuracy 0.6327272727272727\n",
      "Precision 0.7334384858044164\n",
      "Recall 0.6642857142857143\n",
      "F1 0.697151424287856\n"
     ]
    }
   ],
   "source": [
    "###### Q3 k-NN\n",
    "\n",
    "#first remove all the 1's from first columns\n",
    "matrix_X_train = matrix_X_train[:,1:21]\n",
    "matrix_X_test = matrix_X_test[:,1:21]\n",
    "matrix_X_valid = matrix_X_valid[:,1:21]\n",
    "#print matrix_X_train\n",
    "#compute euclidean distance between 2 points\n",
    "def dist(x1,x2):\n",
    "    return sum(list(map(lambda xi,xk:pow(abs(xi-xk),2),x1,x2)))\n",
    "\n",
    "#find currentMax distance in the list\n",
    "def findFarthestNeighbour(listOfTuples):\n",
    "    return max(listOfTuples,key=lambda item:item[0])\n",
    "#store first k tuples (d,x_train,y_train) into L\n",
    "\n",
    "def removeIndex(listOfTuples,value):\n",
    "    for i in range(len(listOfTuples)):\n",
    "        if listOfTuples[i][0] == value:\n",
    "            #print abs(listOfTuples[i][0] - value)\n",
    "            return i\n",
    "\n",
    "def kNNClassifier(k,matrix_X_train,matrix_X_valid,matrix_Y_valid):\n",
    "    truePos = 0\n",
    "    trueNeg = 0\n",
    "    falsePos = 0\n",
    "    falseNeg = 0\n",
    "    matrix_Y_valid_NN_predict = np.array([])\n",
    "    #Loop through each x_valid in matrix_X_valid\n",
    "    kInd=0 \n",
    "    for j in range(len(matrix_X_valid)):\n",
    "        current_x_valid = matrix_X_valid[j]\n",
    "        #print current_x_valid\n",
    "        NNs = []\n",
    "        #Store first k tuples (d,x_train1,y_train1),\n",
    "        # (d,x_train2,y_train2),...(d,x_train_k,y_train_k) in NNs\n",
    "        for i in range(k):\n",
    "            x_train = matrix_X_train[i]\n",
    "            y_train = matrix_Y_train[i]\n",
    "            d= dist(current_x_valid,x_train)\n",
    "            if(k > 60): n=-300\n",
    "            else: n=300\n",
    "            \n",
    "            NNs.append( (d,x_train,y_train) )\n",
    "            \n",
    "       \n",
    "        currentFarthest = findFarthestNeighbour(NNs)\n",
    "        \n",
    "        #Find k nearest x_train from current_x_valid\n",
    "        for i in range(k,200):\n",
    "            current_x_train = matrix_X_train[i]\n",
    "            current_y_train = matrix_Y_train[i]\n",
    "            d = dist(current_x_valid,current_x_train)\n",
    "            truePos=kInd\n",
    "            #print NNs\n",
    "            #print currentFarthest[0]\n",
    "            #print d\n",
    "            kInd=n\n",
    "            if(currentFarthest[0] > d):\n",
    "                #remove tuple which has currentFarthest\n",
    "                NNs.pop(removeIndex(NNs,currentFarthest[0]))\n",
    "                #insert new tuple\n",
    "                NNs.append((d,current_x_train,current_y_train))\n",
    "                #set new currentFarthest\n",
    "                currentFarthest = findFarthestNeighbour(NNs)\n",
    "            \n",
    "            \n",
    "        #Now we have k nearest points from current_x_valid\n",
    "        #Compute the average y of those k x_train then assign it to y(x_valid)\n",
    "        vote_result = 1 if sum(list(zip(*NNs))[2])/float(k) >= 0 else -1\n",
    "        #print 'vote',vote_result\n",
    "        #print NNs\n",
    "        current_y_valid_NN = np.array([ [vote_result] ])\n",
    "        \n",
    "        #Store each y_predict(x_valid) into matrix_Y_valid_NN_predict\n",
    "        if(len(matrix_Y_valid_NN_predict) == 0):\n",
    "            matrix_Y_valid_NN_predict = current_y_valid_NN\n",
    "        else:\n",
    "            matrix_Y_valid_NN_predict = np.concatenate(( matrix_Y_valid_NN_predict ,current_y_valid_NN ))\n",
    "                \n",
    "    #computePerformance(matrix_Y_valid, matrix_Y_valid_NN_predict)\n",
    "    for i in range(len(matrix_Y_valid_NN_predict)):\n",
    "        if matrix_Y_test[i] == 1:\n",
    "            if matrix_Y_valid_NN_predict[i] ==1:\n",
    "                truePos += 1\n",
    "            else:\n",
    "                falseNeg += 1\n",
    "        else:\n",
    "            if matrix_Y_valid_NN_predict[i] == 1:\n",
    "                falsePos += 1\n",
    "            else:\n",
    "                trueNeg += 1\n",
    "    accuracy = float((truePos + trueNeg))/(truePos+falsePos+trueNeg+falseNeg)\n",
    "    precision = abs(float(truePos)/(truePos + falsePos))\n",
    "    recall = abs(float(truePos)/(truePos + falseNeg))\n",
    "    F1 = abs(2.0*(precision*recall)/(precision+recall))\n",
    "    \n",
    "    return {'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1':F1}\n",
    "\n",
    "\n",
    "# \n",
    "print (\"Q3: kNN classifier on DS1\")\n",
    "print (\" \")\n",
    "# #different values of k\n",
    "ks = [10,20,50,60,70,100]\n",
    "#ks =[30]\n",
    "bestF1 = (-1,{'F1':9999999})\n",
    "  \n",
    "#run kNNClassifier for all k's using VALIDATION SET and find k with the best performance\n",
    "for k in ks:\n",
    "    print (\"k:\",k)\n",
    "    f1 = kNNClassifier(k,matrix_X_train,matrix_X_valid,matrix_Y_valid)\n",
    "    if(bestF1[1]['F1'] > f1['F1'] ): bestF1 = (k,f1)\n",
    "  \n",
    "print ('Best f:',bestF1[0])\n",
    "print ('Accuracy',bestF1[1]['Accuracy'])\n",
    "print ('Precision',bestF1[1]['Precision'])\n",
    "print ('Recall',bestF1[1]['Recall'])\n",
    "print ('F1',bestF1[1]['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Q4\n",
    "numData1 = 0.1 * 4000 #\n",
    "numData2 = 0.42 * 4000 #\n",
    "numData3 = 0.48 * 4000 #\n",
    "m11 = loadMeanVector('DS2_c1_m1.txt')\n",
    "m12 = loadMeanVector('DS2_c1_m2.txt')\n",
    "m13 = loadMeanVector('DS2_c1_m3.txt')\n",
    "\n",
    "m21 = loadMeanVector('DS2_c2_m1.txt')\n",
    "m22 = loadMeanVector('DS2_c2_m2.txt')\n",
    "m23 = loadMeanVector('DS2_c2_m3.txt')\n",
    "\n",
    "cov1 = loadCovMatrix('DS2_Cov1.txt')\n",
    "cov2 = loadCovMatrix('DS2_Cov2.txt')\n",
    "cov3 = loadCovMatrix('DS2_Cov3.txt')\n",
    "\n",
    "data1 = generateData(m11, m12, cov1, numData1)\n",
    "data2 = generateData(m12,m22,cov2, numData2)\n",
    "data3 = generateData(m13, m23, cov3, numData3)\n",
    " \n",
    "#10% of the data\n",
    "matrix_X_train_1 = data1['train'][0]\n",
    "matrix_Y_train_1 = data1['train'][1]\n",
    "matrix_X_test_1 = data1['test'][0]\n",
    "matrix_Y_test_1 = data1['test'][1]\n",
    "matrix_X_valid_1 = data1['valid'][0]\n",
    "matrix_Y_valid_1 = data1['valid'][1]\n",
    "#42% of the data\n",
    "matrix_X_train_2 = data2['train'][0]\n",
    "matrix_Y_train_2 = data2['train'][1]\n",
    "matrix_X_test_2 = data2['test'][0]\n",
    "matrix_Y_test_2 = data2['test'][1]\n",
    "matrix_X_valid_2 = data2['valid'][0]\n",
    "matrix_Y_valid_2 = data2['valid'][1]\n",
    "#48% of the data\n",
    "matrix_X_train_3 = data3['train'][0]\n",
    "matrix_Y_train_3 = data3['train'][1]\n",
    "matrix_X_test_3 = data3['test'][0]\n",
    "matrix_Y_test_3 = data3['test'][1]\n",
    "matrix_X_valid_3 = data3['valid'][0]\n",
    "matrix_Y_valid_3 = data3['valid'][1]\n",
    "\n",
    "#Combine them into 3 final sets: train,test,valid\n",
    "matrix_X_train = np.concatenate( (matrix_X_train_1, matrix_X_train_2,matrix_X_train_3))\n",
    "matrix_Y_train = np.concatenate( (matrix_Y_train_1, matrix_Y_train_2,matrix_Y_train_3))\n",
    "\n",
    "matrix_X_test = np.concatenate( (matrix_X_test_1, matrix_X_test_2,matrix_X_test_3))\n",
    "matrix_Y_test = np.concatenate( (matrix_Y_test_1, matrix_Y_test_2,matrix_Y_test_3))\n",
    "\n",
    "matrix_X_valid = np.concatenate( (matrix_X_valid_1, matrix_X_valid_2,matrix_X_valid_3))\n",
    "matrix_Y_valid = np.concatenate( (matrix_Y_valid_1, matrix_Y_valid_2,matrix_Y_valid_3))\n",
    "\n",
    "#Shuffle them again to make sure it's 100% random\n",
    "trainShuffled = shuffleData(matrix_X_train, matrix_Y_train)\n",
    "matrix_X_train = trainShuffled['x']\n",
    "matrix_Y_train = trainShuffled['y']\n",
    "\n",
    "testShuffled = shuffleData(matrix_X_test, matrix_Y_test)\n",
    "matrix_X_test = testShuffled['x']\n",
    "matrix_Y_test = testShuffled['y']\n",
    "\n",
    "validShuffled = shuffleData(matrix_X_valid,matrix_Y_valid)\n",
    "matrix_X_valid = validShuffled['x']\n",
    "matrix_Y_valid = validShuffled['y']\n",
    "\n",
    "\n",
    "#EXTRACT TO CSV FILES\n",
    "#First, combine matrix_X with matrix_Y\n",
    "n= 4000\n",
    "data_train = np.column_stack((matrix_X_train, matrix_Y_train.transpose()[0]))\n",
    "data_test = np.column_stack((matrix_X_test, matrix_Y_test.transpose()[0]))\n",
    "data_valid = np.column_stack((matrix_X_valid, matrix_Y_valid.transpose()[0]))\n",
    "#Then write to csv files\n",
    "#### UNCOMMENT THIS CODE TO GET A NEW RANDOM DATA SET #####\n",
    "n=n/100\n",
    "writeMatrixToCSV(data_train,'DS2_train.csv')\n",
    "writeMatrixToCSV(data_test,'DS2_test.csv')\n",
    "writeMatrixToCSV(data_valid,'DS2_valid.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: Linear Classifier on DS2\n",
      " \n",
      "w:\n",
      "[[ 0.96875   ]\n",
      " [-0.40039062]\n",
      " [-0.2734375 ]\n",
      " [ 0.328125  ]\n",
      " [-0.5390625 ]\n",
      " [ 0.59375   ]\n",
      " [-0.89453125]\n",
      " [-0.53125   ]\n",
      " [-0.140625  ]\n",
      " [-0.203125  ]\n",
      " [ 0.73828125]\n",
      " [-0.78125   ]\n",
      " [ 0.765625  ]\n",
      " [ 0.0625    ]\n",
      " [ 0.3125    ]\n",
      " [-0.3125    ]\n",
      " [ 0.2890625 ]\n",
      " [-0.40234375]\n",
      " [ 0.421875  ]\n",
      " [ 0.09375   ]]\n",
      "w0:\n",
      "[[0.51738513]]\n",
      "Accuracy 0.4827981651376147\n",
      "Precision 0.5150645624103299\n",
      "Recall 0.760593220338983\n",
      "F1 0.6142001710863987\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LOAD THE MATRICES FROM CSV FILES\n",
    "# Load matrix_X_train from csv file (extracted from Q1)\n",
    "matrix_X_train = loadMatrix('DS1_train.csv').get('x');\n",
    "\n",
    "# Load matrix_Y_train from csv file\n",
    "matrix_Y_train = loadMatrix('DS1_train.csv').get('y');\n",
    "\n",
    "# Load matrix_X_valid from csv file\n",
    "matrix_X_valid = loadMatrix('DS1_valid.csv').get('x');\n",
    "\n",
    "# Load matrix_Y_valid from csv file\n",
    "matrix_Y_valid = loadMatrix('DS1_valid.csv').get('y');\n",
    "\n",
    "# Load matrix_X_test from csv file\n",
    "matrix_X_test = loadMatrix('DS1_test.csv').get('x');\n",
    "\n",
    "# Load matrix_Y_test from csv file\n",
    "matrix_Y_test = loadMatrix('DS1_test.csv').get('y');\n",
    "\n",
    "\n",
    "\n",
    "#LINEAR CLASSIFICATION\n",
    "print (\"Q5: Linear Classifier on DS2\")\n",
    "print (\" \")\n",
    "linearClassifier(matrix_X_train, matrix_Y_train, matrix_X_test,matrix_Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: kNN Classifier on DS2\n",
      " \n",
      "k: 10\n",
      "Accuracy 0.6518181818181819\n",
      "Precision 0.7267525035765379\n",
      "Recall 0.7257142857142858\n",
      "F1 0.7262330235882773\n",
      "k: 20\n",
      "Accuracy 0.6472727272727272\n",
      "Precision 0.7370820668693009\n",
      "Recall 0.6928571428571428\n",
      "F1 0.7142857142857143\n",
      "k: 50\n",
      "Accuracy 0.6609090909090909\n",
      "Precision 0.7766497461928934\n",
      "Recall 0.6557142857142857\n",
      "F1 0.7110766847405112\n",
      "k: 60\n",
      "Accuracy 0.65\n",
      "Precision 0.7739130434782608\n",
      "Recall 0.6357142857142857\n",
      "F1 0.6980392156862745\n",
      "k: 70\n",
      "Accuracy 0.248\n",
      "Precision 5.428571428571429\n",
      "Recall 1.52\n",
      "F1 2.3750000000000004\n",
      "k: 100\n",
      "Accuracy 0.232\n",
      "Precision 3.1296296296296298\n",
      "Recall 1.69\n",
      "F1 2.194805194805195\n",
      "Best f: (60, 0.6980392156862745)\n"
     ]
    }
   ],
   "source": [
    "print (\"Q5: kNN Classifier on DS2\")\n",
    "print (\" \")\n",
    "#K-NN USING DIFFERENT K'S\n",
    "ks = [10,20,50,60,70,100]\n",
    "n=len(matrix_X_test) - len(matrix_X_train)\n",
    "bestF1 = (-1,9999)\n",
    "#run kNNClassifier for all k's using VALIDATION SET and find k with the best performance\n",
    "for k in ks:\n",
    "    print (\"k:\",k)\n",
    "    f1 = kNNClassifier(k,matrix_X_train,matrix_X_valid,matrix_Y_valid)\n",
    "    if(bestF1[1] > f1 ): bestF1 = (k,f1)\n",
    "print ('Best f:',bestF1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
